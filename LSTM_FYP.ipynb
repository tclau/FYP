{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNx6FJRnuj+hxhOFNpw+ZK3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"sE_AufSDLIXZ"},"outputs":[],"source":["import matplotlib.pyplot as plt # plotting library\n","import numpy as np # this module is useful to work with numerical arrays\n","import pandas as pd \n","import random \n","import torch\n","import torchvision\n","from torchvision import transforms\n","from torch.utils.data import Dataset,DataLoader,random_split\n","from torch.utils.data.sampler import SubsetRandomSampler\n","from torch import nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import math\n","import glob"]},{"cell_type":"code","source":["train_data_full , train_ma_full= [],[]\n","test_data_full , test_ma_full= [],[]\n","\n","files = glob.glob(\"/content/drive/MyDrive/AI_FYP/*1h.csv\")\n","\n","train_data_full , train_ma_full= [],[]\n","test_data_full , test_ma_full= [],[]\n","for f in files:\n","  data_df = pd.read_csv(f)\n","\n","  data_df = data_df[[\"close\"]]\n","\n","  data = data_df.pct_change().dropna()\n","\n","  l = data.shape[0]\n","  idx = int(l*0.8)\n","  train_data= data[:idx]\n","  test_data = data[idx:]\n","\n","  # tmp_train = train_data\n","  # for i in range(99):\n","  #   tmp_train = np.hstack((tmp_train,train_data))\n","\n","  train_data_sli = np.lib.stride_tricks.sliding_window_view(train_data,(168+1,train_data.shape[1])).squeeze().astype(np.float32)\n","\n","  # tmp_test = test_data\n","  # for i in range(99):\n","  #   tmp_test = np.hstack((tmp_test,test_data))\n","\n","  test_data_sli = np.lib.stride_tricks.sliding_window_view(test_data,(168+1,test_data.shape[1])).squeeze().astype(np.float32)\n","\n","  train_data_full.append(train_data_sli)\n","\n","  test_data_full.append(test_data_sli)"],"metadata":{"id":"LIHZ4ry_LMzi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data_full=np.concatenate(train_data_full)\n","test_data_full=np.concatenate(test_data_full)"],"metadata":{"id":"TZ7o4tqiLOHV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_x,train_y = train_data_full[:,:-1],train_data_full[:,-1]\n","test_x,test_y = test_data_full[:,:-1],test_data_full[:,-1]"],"metadata":{"id":"3boelz9fLPSa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ClassDataset(Dataset):\n","    def __init__(self, input,output,threshold):\n","          self.input = torch.tensor(input)\n","\n","          label = []\n","          for num in output:\n","            # row = [0,0,0]\n","            row = [0,0]\n","            if num>threshold:\n","              row[1]=1\n","            elif num<-threshold:\n","              row[0]=1\n","            else:\n","              pass\n","              # row[1]=1\n","            label.append(row)\n","          label = np.array(label).astype(np.float32)\n","          self.label = torch.tensor(label)\n","          self.output = torch.tensor(output)\n","\n","    def __len__(self):\n","        return len(self.input)\n","\n","    def __getitem__(self, idx):\n","        x = self.input[idx].T\n","        y = self.label[idx]\n","\n","        return x,y\n","\n","class line(nn.Module):\n","  def __init__(self,in_lay,out_lay):\n","    super().__init__()\n","    self.lin = nn.Linear(in_lay,out_lay)\n","    self.norm = nn.BatchNorm1d(out_lay)\n","    self.act = nn.LeakyReLU(True)\n","  \n","  def forward(self,x):\n","    y = self.lin(x)\n","    y = self.norm(y)\n","    y = self.act(y)\n","    return y\n","\n","\n","class Classifier(nn.Module):\n","    def __init__(self, input_fea,hidden_units):\n","        super().__init__()\n","        self.input_fea = input_fea  # this is the number of features\n","        self.hidden_units = hidden_units\n","        self.num_layers = 1\n","\n","        self.lstm = nn.LSTM(\n","            input_size=input_fea,\n","            hidden_size=hidden_units,\n","            batch_first=True,\n","            num_layers=self.num_layers\n","        )\n","\n","    def forward(self,x):\n","      batch_size = x.shape[0]\n","      h0 = torch.zeros(self.num_layers, batch_size, self.hidden_units).requires_grad_()\n","      c0 = torch.zeros(self.num_layers, batch_size, self.hidden_units).requires_grad_()\n","        \n","      _, (hn, _) = self.lstm(x, (h0, c0))\n","      x = self.linear(hn[0]).flatten()\n","      return x"],"metadata":{"id":"PGgNWxBJLQRu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_set = ClassDataset(train_x.reshape(train_x.shape[0],train_x.shape[1],1),train_y,0)\n","test_set = ClassDataset(test_x.reshape(test_x.shape[0],test_x.shape[1],1),test_y,0)\n","\n","BATCH_SIZE = 1024\n","train_loader = DataLoader(train_set,batch_size=BATCH_SIZE)\n","test_loader = DataLoader(test_set,batch_size=BATCH_SIZE)"],"metadata":{"id":"PPaXx8XhLTMY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for x,l in train_loader:\n","  print(x.shape)\n","  break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TqiZpEuiLvUB","executionInfo":{"status":"ok","timestamp":1676013454708,"user_tz":-480,"elapsed":410,"user":{"displayName":"Tc lau","userId":"14708594780097795578"}},"outputId":"3057f522-ee2c-4309-b67a-267f4f5bdade"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1024, 1, 168])\n"]}]},{"cell_type":"code","source":["def multi_acc(y_pred, y_test):\n","    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n","    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1) \n","    _, lab = torch.max(y_test,dim=1)   \n","    \n","    correct_pred = (y_pred_tags == lab).float()\n","    acc = correct_pred.sum() / len(correct_pred)\n","    \n","    acc = torch.round(acc * 100)\n","    \n","    return acc,y_pred_tags"],"metadata":{"id":"9BkLeyiJLUTC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 50\n","lr = 0.0001\n","use_cuda = 1\n","device = torch.device(\"cuda\" if (torch.cuda.is_available() & use_cuda) else \"cpu\")\n","\n","model = Classifier().to(device)\n","criterion = nn.CrossEntropyLoss().to(device)\n","optimizer = torch.optim.SGD(model.parameters(), lr=lr)"],"metadata":{"id":"KNDPO5PAMN0q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for epoch in range(20)[:1]:  # loop over the dataset multiple times\n","\n","    total_loss = 0.0\n","    for i, data in enumerate(train_loader, 0):\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","        print(inputs.size())\n","        # forward + backward + optimize\n","        outputs = model(inputs)\n","        print(outputs.shape)\n","        break\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print statistics\n","        total_loss += loss.item()\n","    total_loss /= len(train_loader.dataset)\n","    if epoch % 1 ==0:\n","      print('[{}/{}] Loss:'.format(epoch+1, epochs), total_loss)\n","      with torch.no_grad():\n","        model.eval()\n","        test_acc = 0\n","        for inputs,labels in test_loader:\n","          inputs = inputs.to(device)\n","          labels = labels.to(device)\n","          outputs = model(inputs)\n","\n","          acc ,pred_tag= multi_acc(outputs, labels)\n","          test_acc += acc.item()\n","        test_acc = test_acc/len(test_loader)\n","      print('[{}/{}] Test Accuracy:'.format(epoch+1, epochs), test_acc)\n","    \n","\n","print('[{}/{}] Loss:'.format(epoch+1, epochs), total_loss)"],"metadata":{"id":"5Qmp-wWsLVSW","colab":{"base_uri":"https://localhost:8080/","height":408},"executionInfo":{"status":"error","timestamp":1676013602781,"user_tz":-480,"elapsed":4,"user":{"displayName":"Tc lau","userId":"14708594780097795578"}},"outputId":"9e7f16d3-fa00-44ed-a82a-7fb49241373d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1024, 1, 168])\n","torch.Size([1024, 32, 162])\n","[1/50] Loss: 0.0\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-16051e8e7273>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m           \u001b[0macc\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mpred_tag\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmulti_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m           \u001b[0mtest_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-40619fde70cf>\u001b[0m in \u001b[0;36mmulti_acc\u001b[0;34m(y_pred, y_test)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcorrect_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_pred_tags\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (162) must match the size of tensor b (1024) at non-singleton dimension 1"]}]}]}